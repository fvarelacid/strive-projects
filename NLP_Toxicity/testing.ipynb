{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    x, y = make_multilabel_classification(\n",
    "        n_samples=10000, n_features=150, n_classes=6, n_labels=2, random_state=1\n",
    "    )\n",
    "    # use 9900 samples for training\n",
    "    x_train = x[:9900]\n",
    "    y_train = y[:9900]\n",
    "    # use 100 samples for testing\n",
    "    x_test = x[-100:]\n",
    "    y_test = y[-100:]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[1][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 2., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 0., 0., 3.],\n",
       "        [0., 0., 0., ..., 1., 1., 0.],\n",
       "        [1., 0., 1., ..., 1., 0., 0.]]),\n",
       " array([[0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 1, 1],\n",
       "        [0, 1, 0, 0, 0, 0]]),\n",
       " array([[2., 0., 1., ..., 1., 0., 2.],\n",
       "        [0., 0., 1., ..., 0., 1., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 1., 0., ..., 0., 1., 0.]]),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 1, 0],\n",
       "        [1, 0, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 1],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [1, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 1, 0, 1],\n",
       "        [1, 0, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        features = self.x[index, :]\n",
    "        labels = self.y[index, :]\n",
    "        \n",
    "        # we have 12 feature columns \n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "        # there are 5 classes and each class can have a binary value ...\n",
    "        # ... either 0 or 1\n",
    "        label1 = torch.tensor(labels[0], dtype=torch.float32)\n",
    "        label2 = torch.tensor(labels[1], dtype=torch.float32)\n",
    "        label3 = torch.tensor(labels[2], dtype=torch.float32)\n",
    "        label4 = torch.tensor(labels[3], dtype=torch.float32)\n",
    "        label5 = torch.tensor(labels[4], dtype=torch.float32)\n",
    "        label6 = torch.tensor(labels[4], dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            'features': features,\n",
    "            'label1': label1,\n",
    "            'label2': label2,\n",
    "            'label3': label3,\n",
    "            'label4': label4,\n",
    "            'label5': label5,\n",
    "            'label6': label6\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BinaryDataset at 0x7f879e393d90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BinaryDataset(dataset[0], dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_dataset = BinaryDataset(dataset[0], dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 2., 1., 0., 0., 0., 0., 0., 0., 0., 2., 1., 0., 1., 0., 0., 0.,\n",
       "        2., 0., 2., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 2., 0.,\n",
       "        2., 0., 0., 0., 0., 0., 2., 0., 0., 0., 1., 0., 1., 2., 0., 0., 0., 0.,\n",
       "        0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_dataset[0]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadBinaryModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadBinaryModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(150, 32) # 150 is the number of features\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 128)\n",
    "        self.fc4 = nn.Linear(128, 256)\n",
    "        \n",
    "        # we will treat each head as a binary classifier ...\n",
    "        # ... so the output features will be 1\n",
    "        self.out1 = nn.Linear(256, 1)\n",
    "        self.out2 = nn.Linear(256, 1)\n",
    "        self.out3 = nn.Linear(256, 1)\n",
    "        self.out4 = nn.Linear(256, 1)\n",
    "        self.out5 = nn.Linear(256, 1)\n",
    "        self.out6 = nn.Linear(256, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "        # each binary classifier head will have its own output\n",
    "        out1 = F.sigmoid(self.out1(x))\n",
    "        out2 = F.sigmoid(self.out2(x))\n",
    "        out3 = F.sigmoid(self.out3(x))\n",
    "        out4 = F.sigmoid(self.out4(x))\n",
    "        out5 = F.sigmoid(self.out5(x))\n",
    "        out6 = F.sigmoid(self.out6(x))\n",
    "        \n",
    "        return out1, out2, out3, out4, out5, out6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# custom loss function for multi-head binary classification\n",
    "def binary_loss_fn(outputs, targets):\n",
    "    o1, o2, o3, o4, o5, o6 = outputs\n",
    "    t1, t2, t3, t4, t5, t6 = targets\n",
    "    l1 = nn.BCELoss()(o1, t1)\n",
    "    l2 = nn.BCELoss()(o2, t2)\n",
    "    l3 = nn.BCELoss()(o3, t3)\n",
    "    l4 = nn.BCELoss()(o4, t4)\n",
    "    l5 = nn.BCELoss()(o5, t5)\n",
    "    l6 = nn.BCELoss()(o6, t6)\n",
    "    return (l1 + l2 + l3 + l4 + l5 + l6) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Number of training samples: 9900\n",
      "[INFO]: Number of training features: 150\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "x_train, y_train, _, _ = make_dataset()\n",
    "# print some info\n",
    "print(f\"[INFO]: Number of training samples: {x_train.shape[0]}\")\n",
    "print(f\"[INFO]: Number of training features: {x_train.shape[1]}\")\n",
    "# train dataset\n",
    "train_dataset = BinaryDataset(x_train, y_train)\n",
    "# train data loader\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "# initialize the model\n",
    "model = MultiHeadBinaryModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 150])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadBinaryModel(\n",
       "  (fc1): Linear(in_features=150, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (out1): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out3): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out5): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out6): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 100\n",
    "# load the model on to the computation device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.4883],\n",
      "        [0.4909],\n",
      "        [0.4907],\n",
      "        [0.4919],\n",
      "        [0.4928],\n",
      "        [0.4922],\n",
      "        [0.4899],\n",
      "        [0.4916],\n",
      "        [0.4904],\n",
      "        [0.4909],\n",
      "        [0.4899],\n",
      "        [0.4910],\n",
      "        [0.4933],\n",
      "        [0.4915],\n",
      "        [0.4924],\n",
      "        [0.4930]], grad_fn=<SigmoidBackward>), tensor([[0.4881],\n",
      "        [0.4873],\n",
      "        [0.4863],\n",
      "        [0.4869],\n",
      "        [0.4863],\n",
      "        [0.4868],\n",
      "        [0.4860],\n",
      "        [0.4871],\n",
      "        [0.4865],\n",
      "        [0.4885],\n",
      "        [0.4870],\n",
      "        [0.4873],\n",
      "        [0.4888],\n",
      "        [0.4889],\n",
      "        [0.4874],\n",
      "        [0.4858]], grad_fn=<SigmoidBackward>), tensor([[0.4993],\n",
      "        [0.4987],\n",
      "        [0.4992],\n",
      "        [0.5000],\n",
      "        [0.4969],\n",
      "        [0.4973],\n",
      "        [0.4965],\n",
      "        [0.4992],\n",
      "        [0.4980],\n",
      "        [0.4986],\n",
      "        [0.4988],\n",
      "        [0.4953],\n",
      "        [0.4989],\n",
      "        [0.4981],\n",
      "        [0.4975],\n",
      "        [0.4999]], grad_fn=<SigmoidBackward>), tensor([[0.4803],\n",
      "        [0.4797],\n",
      "        [0.4802],\n",
      "        [0.4815],\n",
      "        [0.4819],\n",
      "        [0.4812],\n",
      "        [0.4809],\n",
      "        [0.4825],\n",
      "        [0.4826],\n",
      "        [0.4806],\n",
      "        [0.4818],\n",
      "        [0.4831],\n",
      "        [0.4797],\n",
      "        [0.4798],\n",
      "        [0.4803],\n",
      "        [0.4790]], grad_fn=<SigmoidBackward>), tensor([[0.4817],\n",
      "        [0.4798],\n",
      "        [0.4820],\n",
      "        [0.4816],\n",
      "        [0.4803],\n",
      "        [0.4814],\n",
      "        [0.4792],\n",
      "        [0.4843],\n",
      "        [0.4819],\n",
      "        [0.4796],\n",
      "        [0.4829],\n",
      "        [0.4793],\n",
      "        [0.4814],\n",
      "        [0.4827],\n",
      "        [0.4813],\n",
      "        [0.4778]], grad_fn=<SigmoidBackward>), tensor([[0.4809],\n",
      "        [0.4800],\n",
      "        [0.4800],\n",
      "        [0.4819],\n",
      "        [0.4805],\n",
      "        [0.4818],\n",
      "        [0.4797],\n",
      "        [0.4814],\n",
      "        [0.4799],\n",
      "        [0.4796],\n",
      "        [0.4800],\n",
      "        [0.4801],\n",
      "        [0.4803],\n",
      "        [0.4790],\n",
      "        [0.4801],\n",
      "        [0.4820]], grad_fn=<SigmoidBackward>))\n",
      "(tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.]), tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.]), tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for data in train_dataloader:\n",
    "\n",
    "    # extract the features and labels\n",
    "    features = data['features'].to(device)\n",
    "    target1 = data['label1'].to(device)\n",
    "    target2 = data['label2'].to(device)\n",
    "    target3 = data['label3'].to(device)\n",
    "    target4 = data['label4'].to(device)\n",
    "    target5 = data['label5'].to(device)\n",
    "    target6 = data['label6'].to(device)\n",
    "    \n",
    "    \n",
    "    outputs = model(features)\n",
    "    targets = (target1, target2, target3, target4, target5, target6)\n",
    "\n",
    "    print(outputs)\n",
    "    print(targets)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train(model, dataloader, optimizer, loss_fn, train_dataset, device):\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    train_running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_dataset)/dataloader.batch_size)):\n",
    "        counter += 1\n",
    "        \n",
    "        # extract the features and labels\n",
    "        features = data['features'].to(device)\n",
    "        target1 = data['label1'].to(device)\n",
    "        target2 = data['label2'].to(device)\n",
    "        target3 = data['label3'].to(device)\n",
    "        target4 = data['label4'].to(device)\n",
    "        target5 = data['label5'].to(device)\n",
    "        target6 = data['label6'].to(device)\n",
    "        \n",
    "        # zero-out the optimizer gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(features)\n",
    "        targets = (target1, target2, target3, target4, target5, target6)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update optimizer parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_running_loss / counter\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadBinaryModel(\n",
       "  (fc1): Linear(in_features=150, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (out1): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out3): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out5): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out6): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning parameters\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 100\n",
    "# load the model on to the computation device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]/Users/franciscovarelacid/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/franciscovarelacid/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1024])) that is different to the input size (torch.Size([1024, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "100%|██████████| 9/9 [00:03<00:00,  4.41it/s]/Users/franciscovarelacid/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([684])) that is different to the input size (torch.Size([684, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "10it [00:03,  3.06it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8026\n",
      "Epoch 2 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6905\n",
      "Epoch 3 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  4.76it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6513\n",
      "Epoch 4 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  6.15it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6379\n",
      "Epoch 5 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  6.66it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6153\n",
      "Epoch 6 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  9.09it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5797\n",
      "Epoch 7 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.40it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5463\n",
      "Epoch 8 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.68it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5234\n",
      "Epoch 9 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5095\n",
      "Epoch 10 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  5.74it/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4939\n",
      "Epoch 11 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4723"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/gtp4f1sn19g4t4r5r42dd34m0000gn/T/ipykernel_20961/2613440748.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Loss: {train_epoch_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs/multi_head_binary.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 )\n\u001b[1;32m    540\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the training\n",
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = train(\n",
    "        model, train_dataloader, optimizer, binary_loss_fn, train_dataset, device\n",
    "    )\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "torch.save(model.state_dict(), 'outputs/multi_head_binary.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and save the train loss graph\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('outputs/multi_head_binary_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Number of test samples: 100\n",
      "[INFO]: Number of test features: 150\n"
     ]
    }
   ],
   "source": [
    "_, _, x_test, y_test = make_dataset()\n",
    "# print some info\n",
    "print(f\"[INFO]: Number of test samples: {x_test.shape[0]}\")\n",
    "print(f\"[INFO]: Number of test features: {x_test.shape[1]}\")\n",
    "test_dataset = BinaryDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadBinaryModel(\n",
       "  (fc1): Linear(in_features=150, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (out1): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out3): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out5): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (out6): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the trained model\n",
    "model = MultiHeadBinaryModel()\n",
    "model.load_state_dict(torch.load('outputs/multi_head_binary.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE 0\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 1\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 2\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 3\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 1, 1]\n",
      "SAMPLE 4\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 1, 1]\n",
      "GROUND TRUTHS: [1, 0, 0, 1, 0, 0]\n",
      "SAMPLE 5\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 6\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 7\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 0, 0]\n",
      "SAMPLE 8\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 0, 0]\n",
      "SAMPLE 9\n",
      "ALL PREDICTIONS: [0, 0, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n",
      "SAMPLE 10\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 11\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 12\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 1, 1, 1, 1]\n",
      "SAMPLE 13\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 1, 0, 0]\n",
      "SAMPLE 14\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 15\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 16\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 0, 0]\n",
      "SAMPLE 17\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 18\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 19\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 1, 1]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 1, 1]\n",
      "SAMPLE 20\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n",
      "SAMPLE 21\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 22\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 1, 0, 0]\n",
      "SAMPLE 23\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 1, 1]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 24\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 25\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 1, 0, 0]\n",
      "SAMPLE 26\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 27\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 28\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 29\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n",
      "SAMPLE 30\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 31\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 32\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 0, 0]\n",
      "SAMPLE 33\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 1, 1]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 34\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 35\n",
      "ALL PREDICTIONS: [0, 0, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 1, 0, 0]\n",
      "SAMPLE 36\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 37\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 38\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscovarelacid/opt/anaconda3/envs/nlpmod/lib/python3.8/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE 39\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 1, 1]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 1, 1]\n",
      "SAMPLE 40\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 41\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 42\n",
      "ALL PREDICTIONS: [0, 0, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 1, 0, 0]\n",
      "SAMPLE 43\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 44\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 45\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 46\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 47\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 1, 1]\n",
      "SAMPLE 48\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n",
      "SAMPLE 49\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 50\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 51\n",
      "ALL PREDICTIONS: [0, 0, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n",
      "SAMPLE 52\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 53\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 0, 0]\n",
      "SAMPLE 54\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 0, 0]\n",
      "SAMPLE 55\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 1, 1]\n",
      "GROUND TRUTHS: [1, 1, 1, 1, 1, 1]\n",
      "SAMPLE 56\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 57\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 58\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 59\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 60\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 61\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 1, 1]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 1, 1]\n",
      "SAMPLE 62\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 63\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 64\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 65\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 1, 1]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 66\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 67\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 68\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 1, 1]\n",
      "SAMPLE 69\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 70\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 71\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 1, 1]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 1, 1]\n",
      "SAMPLE 72\n",
      "ALL PREDICTIONS: [0, 0, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 73\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n",
      "SAMPLE 74\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 0, 0]\n",
      "SAMPLE 75\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 1, 1]\n",
      "GROUND TRUTHS: [1, 0, 0, 1, 0, 0]\n",
      "SAMPLE 76\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 77\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 78\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 1, 1]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 1, 1]\n",
      "SAMPLE 79\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 80\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 1, 1]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 81\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 1, 1]\n",
      "GROUND TRUTHS: [0, 0, 0, 1, 1, 1]\n",
      "SAMPLE 82\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 83\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 84\n",
      "ALL PREDICTIONS: [0, 0, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 1, 0, 0]\n",
      "SAMPLE 85\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 0, 0, 0]\n",
      "SAMPLE 86\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 1, 1]\n",
      "SAMPLE 87\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 0, 0]\n",
      "SAMPLE 88\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 89\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 90\n",
      "ALL PREDICTIONS: [0, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 91\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 1, 1]\n",
      "SAMPLE 92\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 1, 1]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n",
      "SAMPLE 93\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 94\n",
      "ALL PREDICTIONS: [1, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 0, 0, 0, 0, 0]\n",
      "SAMPLE 95\n",
      "ALL PREDICTIONS: [1, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 96\n",
      "ALL PREDICTIONS: [0, 0, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [1, 1, 0, 1, 1, 1]\n",
      "SAMPLE 97\n",
      "ALL PREDICTIONS: [0, 1, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 0, 0, 0]\n",
      "SAMPLE 98\n",
      "ALL PREDICTIONS: [0, 1, 0, 1, 0, 0]\n",
      "GROUND TRUTHS: [0, 1, 0, 1, 0, 0]\n",
      "SAMPLE 99\n",
      "ALL PREDICTIONS: [1, 0, 0, 0, 0, 0]\n",
      "GROUND TRUTHS: [1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i, test_sample in enumerate(test_dataloader):\n",
    "    print(f\"SAMPLE {i}\")\n",
    "    # extract the features and labels\n",
    "    features = test_sample['features'].to(device)\n",
    "    target1 = test_sample['label1'].to(device)\n",
    "    target2 = test_sample['label2'].to(device)\n",
    "    target3 = test_sample['label3'].to(device)\n",
    "    target4 = test_sample['label4'].to(device)\n",
    "    target5 = test_sample['label5'].to(device)\n",
    "    target6 = test_sample['label6'].to(device)\n",
    "    \n",
    "    outputs = model(features)\n",
    "            \n",
    "    # get all the labels\n",
    "    all_labels = []\n",
    "    for out in outputs:\n",
    "        if out >= 0.5:\n",
    "            all_labels.append(1)\n",
    "        else:\n",
    "            all_labels.append(0)\n",
    "    \n",
    "    targets = (target1, target2, target3, target4, target5, target6)\n",
    "    \n",
    "    # get all the targets in int format from tensor format\n",
    "    all_targets = []\n",
    "    for target in targets:\n",
    "        all_targets.append(int(target.squeeze(0).detach().cpu()))\n",
    "            \n",
    "    print(f\"ALL PREDICTIONS: {all_labels}\")\n",
    "    print(f\"GROUND TRUTHS: {all_targets}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be2cbdda8aa2f9b96b178970cd0b2401cff75b5326fdd25c9e5bf06009d8e641"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('nlpmod': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
